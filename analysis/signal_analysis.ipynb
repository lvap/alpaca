{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f9eb2d9",
   "metadata": {},
   "source": [
    "# Signal analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3483732",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0d75a41",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(242, 59)\n",
      "(241, 59)\n",
      "(200, 59)\n",
      "(200, 59)\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import spearmanr\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# load datasets\n",
    "likert_datasets = [\"credcoalition.csv\", \"microsoft.csv\", \"reconcile.csv\"]\n",
    "binary_datasets = [\"fnn-gossip.csv\", \"fnn-politifact.csv\"]\n",
    "\n",
    "likert_per_file = (pd.read_csv(os.path.join(os.getcwd(), \"datasets_evaluated\", dataset), sep=\";\",index_col=\"url\") \n",
    "                   for dataset in likert_datasets)\n",
    "binary_per_file = (pd.read_csv(os.path.join(os.getcwd(), \"datasets_evaluated\", dataset), sep=\";\",index_col=\"url\") \n",
    "                   for dataset in binary_datasets)\n",
    "\n",
    "likert_df = pd.concat(likert_per_file)\n",
    "binary_df = pd.concat(binary_per_file)\n",
    "\n",
    "# swap 0 <-> 1 fake news classification to facilitate comparisons with credibility ratings (higher rating = better)\n",
    "binary_df[\"rating\"] = 1 - binary_df[\"rating\"]\n",
    "\n",
    "# create combined emotion intensity column\n",
    "likert_df[\"emotion_intensity\"] = (likert_df[\"anger_intensity\"] + likert_df[\"anticipation_intensity\"]\n",
    "                                  + likert_df[\"disgust_intensity\"] + likert_df[\"fear_intensity\"]\n",
    "                                  + likert_df[\"sadness_intensity\"] + likert_df[\"joy_intensity\"]\n",
    "                                  + likert_df[\"surprise_intensity\"] + likert_df[\"trust_intensity\"])\n",
    "binary_df[\"emotion_intensity\"] = (binary_df[\"anger_intensity\"] + binary_df[\"anticipation_intensity\"] \n",
    "                                  + binary_df[\"disgust_intensity\"] + binary_df[\"fear_intensity\"]\n",
    "                                  + binary_df[\"sadness_intensity\"] + binary_df[\"joy_intensity\"]\n",
    "                                  + binary_df[\"surprise_intensity\"] + binary_df[\"trust_intensity\"])\n",
    "\n",
    "# dataframes for webpages without headlines\n",
    "likert_clean = likert_df.copy()\n",
    "likert_clean = likert_clean[likert_clean[\"clickbait\"] > -10]\n",
    "binary_clean = binary_df.copy()\n",
    "binary_clean = binary_clean[binary_clean[\"clickbait\"] > -10]\n",
    "\n",
    "# data distributions\n",
    "print(likert_df.shape)\n",
    "print(likert_clean.shape)\n",
    "print(binary_df.shape)\n",
    "print(binary_clean.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aaa63b4",
   "metadata": {},
   "source": [
    "## Signal scores & credibility correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d00ca6aa",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score_url_domain_ending             0.1746552141  0.00645  0.2154101092  0.00219\n",
      "score_ls_sentence_count             0.0217943134  0.73587  0.3637267966  0.00000\n",
      "score_vocabulary_emotional_words    0.1478136029  0.02144  0.2373630623  0.00071\n",
      "score_tonality_exclamations_text    0.2814921193  0.00001  0.0587699187  0.40844\n",
      "score_ls_word_count_text            -0.0090645035  0.88844  0.3246437488  0.00000\n",
      "score_tonality_all_caps_title       0.1171977047  0.06934  0.1959654504  0.00542\n",
      "score_ls_word_count_title           0.1692409064  0.00847  0.1300712538  0.06639\n",
      "score_errors                        0.1569176505  0.01454  0.1184542035  0.09480\n",
      "score_clickbait                     0.1362540513  0.03451  0.1307937102  0.06489\n",
      "score_sentiment_polarity_text       0.0340834574  0.59776  0.2285869206  0.00113\n",
      "score_sentiment_polarity_title      0.1525822066  0.01777  0.0754660009  0.28820\n",
      "score_ls_word_length_text           0.2265133571  0.00038  -0.0092198317  0.89690\n",
      "score_sentiment_subjectivity        0.1203742486  0.06153  0.0835096963  0.23973\n",
      "score_readability                   0.2115890105  0.00093  -0.0329459483  0.64327\n",
      "score_tonality_exclamations_title   0.1236448206  0.05525  0.0458831468  0.51882\n",
      "score_ls_word_length_title          0.0832559186  0.19775  0.0405187857  0.56891\n",
      "score_tonality_all_caps_text        0.1016472245  0.11476  0.0083105870  0.90702\n",
      "score_tonality_questions_text       0.0877682602  0.17354  -0.0328436251  0.64430\n",
      "score_author                        0.0938657991  0.14543  -0.1286239389  0.06950\n",
      "score_vocabulary_profanity          0.0069555670  0.91428  -0.0755928946  0.28739\n",
      "score_tonality_questions_title      -0.1454418075  0.02394  0.0368604890  0.60432\n",
      "score_links_external                -0.2199974999  0.00057  -0.0119101066  0.86707\n",
      "score_ls_type_token_ratio           0.0175255074  0.78620  -0.3563050719  0.00000\n"
     ]
    }
   ],
   "source": [
    "signals = [\"score_author\",\n",
    "           \"score_url_domain_ending\",\n",
    "           \"score_errors\",\n",
    "           \"score_tonality_questions_text\",\n",
    "           \"score_tonality_exclamations_text\",\n",
    "           \"score_tonality_all_caps_text\",\n",
    "           \"score_readability\",\n",
    "           \"score_ls_word_count_text\",\n",
    "           \"score_ls_sentence_count\",\n",
    "           \"score_ls_type_token_ratio\",\n",
    "           \"score_ls_word_length_text\",\n",
    "           \"score_vocabulary_profanity\",\n",
    "           \"score_vocabulary_emotional_words\",\n",
    "           \"score_links_external\",\n",
    "           \"score_sentiment_polarity_text\",\n",
    "           \"score_sentiment_subjectivity\"]\n",
    "\n",
    "headline_signals = [\"score_tonality_questions_title\",\n",
    "                    \"score_tonality_exclamations_title\",\n",
    "                    \"score_tonality_all_caps_title\",\n",
    "                    \"score_ls_word_count_title\",\n",
    "                    \"score_ls_word_length_title\",\n",
    "                    \"score_clickbait\",\n",
    "                    \"score_sentiment_polarity_title\"]\n",
    "\n",
    "correlations = {}\n",
    "\n",
    "for signal in signals:\n",
    "    likert_rho, likert_p = spearmanr(likert_df[signal], likert_df[\"rating\"])\n",
    "    binary_rho, binary_p = spearmanr(binary_df[signal], binary_df[\"rating\"])\n",
    "    correlations[signal] = [likert_rho, likert_p, binary_rho, binary_p]\n",
    "for signal in headline_signals:\n",
    "    likert_rho, likert_p = spearmanr(likert_clean[signal], likert_clean[\"rating\"])\n",
    "    binary_rho, binary_p = spearmanr(binary_clean[signal], binary_clean[\"rating\"])\n",
    "    correlations[signal] = [likert_rho, likert_p, binary_rho, binary_p]\n",
    "    \n",
    "for signal_results in sorted(correlations.items(), key=lambda tpl: tpl[1][0]+ tpl[1][2], reverse=True):\n",
    "    print(\"{:<35} {:.10f}  {:.5f}  {:.10f}  {:.5f}\".format(signal_results[0],\n",
    "                                                            signal_results[1][0], signal_results[1][1],\n",
    "                                                            signal_results[1][2], signal_results[1][3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8574fa8e",
   "metadata": {},
   "source": [
    "## Inter-signal correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dcc00d06",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "readability_coleman_liau & word_length_text                       0.9634364864  0.00000  0.9520573014  0.00000\n",
      "word_count_text & sentence_count                                  0.9454530845  0.00000  0.9446779729  0.00000\n",
      "word_count_text & ttr                                             -0.8559305835  0.00000  -0.9082166511  0.00000\n",
      "sentence_count & ttr                                              -0.8069241993  0.00000  -0.8689474696  0.00000\n",
      "sentence_count & sentiment_text_vader                             0.2912136118  0.00000  0.4283807038  0.00000\n",
      "word_count_text & sentiment_text_vader                            0.2677966195  0.00002  0.4097673730  0.00000\n",
      "sentiment_text_vader & negativity_title_vader                     -0.3741740397  0.00000  -0.2836326293  0.00005\n",
      "questions_text_per_sentence & sentence_count                      0.2210630394  0.00053  0.4028962869  0.00000\n",
      "ttr & sentiment_text_vader                                        -0.2651964823  0.00003  -0.3470119076  0.00000\n",
      "emotion_intensity & negativity_title_vader                        0.2554671879  0.00006  0.3420245788  0.00000\n",
      "word_length_text & word_length_title                              0.2510494946  0.00008  0.3294656658  0.00000\n",
      "readability_coleman_liau & word_length_title                      0.2595489572  0.00005  0.3123923176  0.00001\n",
      "readability_coleman_liau & subjectivity                           -0.1996608018  0.00180  -0.3653221331  0.00000\n",
      "sentiment_text_vader & emotion_intensity                          -0.2521770792  0.00007  -0.2989213315  0.00002\n",
      "exclamations_text_per_sentence & readability_coleman_liau         -0.2921923228  0.00000  -0.2551803638  0.00027\n",
      "word_length_text & subjectivity                                   -0.1949500866  0.00232  -0.3469376734  0.00000\n",
      "exclamations_text_per_sentence & word_length_text                 -0.2687004816  0.00002  -0.2626167219  0.00017\n",
      "questions_text_per_sentence & word_count_text                     0.1377830248  0.03215  0.3547418443  0.00000\n",
      "links_count & score_author                                        0.1866601874  0.00356  0.2967619607  0.00002\n",
      "score_author & word_count_title                                   0.2579528169  0.00005  0.2090377508  0.00297\n",
      "questions_text_per_sentence & readability_coleman_liau            -0.1917420009  0.00274  -0.2720376417  0.00010\n",
      "errors_grammar_spelling & exclamations_text_per_sentence          0.1878731866  0.00335  0.2660813302  0.00014\n",
      "errors_grammar_spelling & all_caps_text                           0.2389945791  0.00017  0.2084085216  0.00306\n",
      "exclamations_text_per_sentence & sentiment_text_vader             0.2453719795  0.00012  0.1741344827  0.01366\n",
      "word_length_text & domain_ending                                  0.2181859710  0.00065  0.1676311586  0.01766\n",
      "questions_text_per_sentence & sentiment_text_vader                0.1428528112  0.02627  0.2327277201  0.00091\n",
      "sentence_count & profanity                                        0.1281067755  0.04651  0.2439159924  0.00050\n",
      "questions_text_per_sentence & word_length_text                    -0.1528988973  0.01730  -0.2189881173  0.00184\n",
      "questions_text_per_sentence & exclamations_text_per_sentence      0.2083239320  0.00111  0.1615357443  0.02230\n",
      "word_count_text & profanity                                       0.1530158699  0.01721  0.2165136711  0.00207\n",
      "ttr & clickbait                                                   -0.1403579819  0.02938  -0.2214034560  0.00163\n",
      "readability_coleman_liau & sentence_count                         -0.1402290933  0.02919  -0.2150086865  0.00223\n",
      "exclamations_text_per_sentence & subjectivity                     0.1700843216  0.00801  0.1618409021  0.02205\n",
      "readability_coleman_liau & score_author                           -0.1651633326  0.01006  -0.1589206672  0.02460\n",
      "errors_grammar_spelling & ttr                                     0.1276315260  0.04733  0.1841360028  0.00905\n"
     ]
    }
   ],
   "source": [
    "signals = [\"errors_grammar_spelling\", \n",
    "           \"questions_text_per_sentence\",\n",
    "           \"exclamations_text_per_sentence\",\n",
    "           \"all_caps_text\",\n",
    "           \"all_caps_title\",\n",
    "           \"readability_coleman_liau\",\n",
    "           \"word_count_text\",\n",
    "           \"sentence_count\",\n",
    "           \"ttr\",\n",
    "           \"word_length_text\",\n",
    "           \"profanity\",\n",
    "           \"links_count\",\n",
    "           \"sentiment_text_vader\",\n",
    "           \"subjectivity\",\n",
    "           \"score_author\",\n",
    "           \"emotion_intensity\"]\n",
    "\n",
    "headline_signals = [\"negativity_title_vader\", \n",
    "                    \"word_length_title\",\n",
    "                    \"word_count_title\",\n",
    "                    \"questions_title\",\n",
    "                    \"exclamations_title\",\n",
    "                    \"clickbait\",\n",
    "                    \"domain_ending\"]\n",
    "\n",
    "correlations = {}\n",
    "\n",
    "# check all possible correlations for signals in the signals list\n",
    "for index, signal in enumerate(signals):\n",
    "        for index2 in range(index + 1, len(signals)):\n",
    "            signal2 = signals[index2]\n",
    "            \n",
    "            likert_rho, likert_p = spearmanr(likert_df[signal], likert_df[signal2])\n",
    "            binary_rho, binary_p = spearmanr(binary_df[signal], binary_df[signal2])\n",
    "            \n",
    "            if likert_p < 0.05 and binary_p < 0.05 and not (likert_rho < 0 < binary_rho or binary_rho < 0 < likert_rho):\n",
    "                correlations[signal + \" & \" + signal2] = [likert_rho, likert_p, binary_rho, binary_p]\n",
    "                \n",
    "# check all possible correlations for a signal in the signals and the other in the headline_signals list\n",
    "for signal in signals:\n",
    "        for signal2 in headline_signals:            \n",
    "            likert_rho, likert_p = spearmanr(likert_clean[signal], likert_clean[signal2])\n",
    "            binary_rho, binary_p = spearmanr(binary_clean[signal], binary_clean[signal2])\n",
    "            \n",
    "            if likert_p < 0.05 and binary_p < 0.05 and not (likert_rho < 0 < binary_rho or binary_rho < 0 < likert_rho):\n",
    "                correlations[signal + \" & \" + signal2] = [likert_rho, likert_p, binary_rho, binary_p]\n",
    "                \n",
    "# check all possible correlations for signals in the headline_signals list\n",
    "for index, signal in enumerate(signals):\n",
    "    for index2 in range(index + 1, len(signals)):\n",
    "        signal2 = signals[index2]\n",
    "\n",
    "        likert_rho, likert_p = spearmanr(likert_df[signal], likert_df[signal2])\n",
    "        binary_rho, binary_p = spearmanr(binary_df[signal], binary_df[signal2])\n",
    "\n",
    "        if likert_p < 0.05 and binary_p < 0.05 and not (likert_rho < 0 < binary_rho or binary_rho < 0 < likert_rho):\n",
    "            correlations[signal + \" & \" + signal2] = [likert_rho, likert_p, binary_rho, binary_p]\n",
    "            \n",
    "for signal_results in sorted(correlations.items(), key=lambda tpl: abs(tpl[1][0] + tpl[1][2]), reverse=True):\n",
    "    print(\"{:<65} {:.10f}  {:.5f}  {:.10f}  {:.5f}\".format(signal_results[0],\n",
    "                                                            signal_results[1][0], signal_results[1][1],\n",
    "                                                            signal_results[1][2], signal_results[1][3]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
